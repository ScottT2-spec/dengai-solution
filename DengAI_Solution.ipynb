{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": []},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": ["# DengAI: Predicting Disease Spread\n", "**XGBoost + LightGBM + CatBoost ensemble**\n\n", "1. Run Cell 1 to install & upload your 3 CSV files\n", "2. Run Cell 2 to train & predict\n", "3. Run Cell 3 to download submission.csv\n", "4. Upload submission.csv to DrivenData"],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": ["!pip install -q xgboost lightgbm catboost\n", "from google.colab import files\n", "print('Select your 3 CSV files: dengue_features_train.csv, dengue_labels_train.csv, dengue_features_test.csv')\n", "uploaded = files.upload()"],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import TimeSeriesSplit\n", "from sklearn.metrics import mean_absolute_error\n", "from xgboost import XGBRegressor\n", "from lightgbm import LGBMRegressor\n", "from catboost import CatBoostRegressor\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "train_features = pd.read_csv('dengue_features_train.csv')\n", "train_labels = pd.read_csv('dengue_labels_train.csv')\n", "test_features = pd.read_csv('dengue_features_test.csv')\n", "train = train_features.merge(train_labels, on=['city','year','weekofyear'])\n", "print(f'Train: {train.shape}, Test: {test_features.shape}')\n", "\n", "def engineer(df):\n", "    df = df.copy()\n", "    df['month'] = pd.to_datetime(df['week_start_date']).dt.month\n", "    df.drop('week_start_date', axis=1, inplace=True)\n", "    df['is_wet'] = df['month'].apply(lambda m: 1 if m in [5,6,7,8,9,10,11] else 0)\n", "    df['week_sin'] = np.sin(2*np.pi*df['weekofyear']/52)\n", "    df['week_cos'] = np.cos(2*np.pi*df['weekofyear']/52)\n", "    ndvi = [c for c in df.columns if 'ndvi' in c]\n", "    climate = [c for c in df.columns if c not in ['city','year','weekofyear','total_cases','month','is_wet','week_sin','week_cos']]\n", "    for city in df.city.unique():\n", "        m = df.city==city\n", "        df.loc[m,climate] = df.loc[m,climate].ffill().bfill()\n", "    df['ndvi_avg'] = df[ndvi].mean(axis=1)\n", "    if 'reanalysis_max_air_temp_k' in df.columns:\n", "        df['temp_range'] = df['reanalysis_max_air_temp_k']-df['reanalysis_min_air_temp_k']\n", "    if 'reanalysis_specific_humidity_g_per_kg' in df.columns:\n", "        df['humid_temp'] = df['reanalysis_specific_humidity_g_per_kg']*df['reanalysis_avg_temp_k']\n", "    precip = [c for c in df.columns if 'precip' in c]\n", "    if precip: df['precip_avg'] = df[precip].mean(axis=1)\n", "    lag_cols = [c for c in ['reanalysis_specific_humidity_g_per_kg','reanalysis_dew_point_temp_k',\n", "        'reanalysis_avg_temp_k','station_avg_temp_c','precipitation_amt_mm','ndvi_avg','humid_temp'] if c in df.columns]\n", "    for city in df.city.unique():\n", "        m = df.city==city\n", "        cd = df.loc[m].copy()\n", "        for col in lag_cols:\n", "            for lag in [1,2,3,4]: df.loc[m,f'{col}_l{lag}'] = cd[col].shift(lag)\n", "            for w in [4,8,12]: df.loc[m,f'{col}_r{w}'] = cd[col].rolling(w,min_periods=1).mean()\n", "            df.loc[m,f'{col}_s4'] = cd[col].rolling(4,min_periods=1).std()\n", "        if 'total_cases' in cd.columns:\n", "            for lag in [1,2,3,4]: df.loc[m,f'cases_l{lag}'] = cd['total_cases'].shift(lag)\n", "            df.loc[m,'cases_r4'] = cd['total_cases'].rolling(4,min_periods=1).mean()\n", "            df.loc[m,'cases_r8'] = cd['total_cases'].rolling(8,min_periods=1).mean()\n", "    return df.ffill().bfill().fillna(0)\n", "\n", "print('Engineering features...')\n", "train_e = engineer(train)\n", "test_e = engineer(test_features)\n", "drop = ['city','total_cases']\n", "fcols = [c for c in train_e.columns if c not in drop]\n", "for c in fcols:\n", "    if c not in test_e.columns: test_e[c]=0\n", "test_e2 = test_e[fcols]\n", "print(f'Features: {len(fcols)}')\n", "\n", "results = {}\n", "for city in ['sj','iq']:\n", "    ct = train_e[train_e.city==city]\n", "    X,y = ct[fcols].values, ct['total_cases'].values\n", "    Xt = test_e2[test_e.city==city].values\n", "    print(f'\\n{city.upper()}: {len(X)} train, {len(Xt)} test')\n", "    all_preds = []\n", "    for seed in [42,123,456,789]:\n", "        models = [\n", "            XGBRegressor(n_estimators=1000,max_depth=5,learning_rate=0.03,subsample=0.8,colsample_bytree=0.7,reg_alpha=0.1,reg_lambda=1,min_child_weight=5,random_state=seed,verbosity=0),\n", "            LGBMRegressor(n_estimators=1000,max_depth=5,learning_rate=0.03,subsample=0.8,colsample_bytree=0.7,reg_alpha=0.1,reg_lambda=1,min_child_samples=10,random_state=seed,verbose=-1),\n", "            CatBoostRegressor(iterations=1000,depth=5,learning_rate=0.03,l2_leaf_reg=3,random_seed=seed,verbose=0),\n", "        ]\n", "        pred = np.zeros(len(Xt))\n", "        for m in models:\n", "            m.fit(X,y)\n", "            pred += m.predict(Xt)/3\n", "        all_preds.append(pred)\n", "    results[city] = np.clip(np.round(np.mean(all_preds,axis=0)),0,None).astype(int)\n", "    tscv = TimeSeriesSplit(n_splits=5)\n", "    scores = []\n", "    for tr,vl in tscv.split(X):\n", "        m = LGBMRegressor(n_estimators=1000,max_depth=5,learning_rate=0.03,random_state=42,verbose=-1)\n", "        m.fit(X[tr],y[tr])\n", "        p = np.clip(np.round(m.predict(X[vl])),0,None)\n", "        scores.append(mean_absolute_error(y[vl],p))\n", "    print(f'  CV MAE: {np.mean(scores):.2f}')\n", "    print(f'  Predictions: min={results[city].min()}, max={results[city].max()}, mean={results[city].mean():.1f}')\n", "\n", "sj_t = test_features[test_features.city=='sj'][['city','year','weekofyear']].copy()\n", "iq_t = test_features[test_features.city=='iq'][['city','year','weekofyear']].copy()\n", "sj_t['total_cases']=results['sj']\n", "iq_t['total_cases']=results['iq']\n", "sub = pd.concat([sj_t,iq_t],ignore_index=True)\n", "sub.to_csv('submission.csv',index=False)\n", "print(f'\\nDone! submission.csv ready ({len(sub)} rows)')"],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["from google.colab import files\n", "files.download('submission.csv')"],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
